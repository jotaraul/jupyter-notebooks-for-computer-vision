{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Operators based on second derivative\n",
    "\n",
    "In the same way as we can detect edges by looking at the gradient (first-derivative) image, it is also possible to do that by analyzing the output of operators based on the second-derivative. \n",
    "\n",
    "First-derivative operators try to detect edges by looking for high magnitude values of such derivatives. Recall this figure shown in the previous section, illustrating two one-dimensional continuous functions $f(x)$ and their first derivatives.\n",
    "\n",
    "<img src=\"./images/second_derivative_of_continuous_function.PNG\" width=\"400\">\n",
    "\n",
    "We now add a third row (c) showing their second derivatives, and we can check how such values correspond to... **zero crossings!**. That is, a second derivative yields a zero-crossing at points where the gradient presents a maximum, so we could detect edges looking for those crossings.\n",
    "\n",
    "Unfortunately, things get a little tricky when moving to a 2D space (like images). Why? because depending on the edge orientation, this zero-crossing may go almost unnoticed (see, for example, c):\n",
    "\n",
    "<img src=\"./images/second_derivatives_of_2D_functions.PNG\" width=\"500\">\n",
    "\n",
    "In this notebook we are going two explore two methods that face such issue and detect edges using the second derivative. These are:\n",
    "\n",
    "- **Laplacian operator** (Section 3.2.1)\n",
    "- **LoG operator** (Section 3.2.2)\n",
    "\n",
    "Additionally, we will also take a look at a widely used algorithm that is a combination of different techniques: the **Canny algorithm** (Section 3.2.3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem context - Edge detection for medical images\n",
    "\n",
    "Unfortunately, you were not accepted (yet!) by the researching team at *Hospital Cl√≠nico* because the obtained results in the previous notebook were not as good as expected. Anyway, they have shown you the algorithms that they are currently using so you can study it for future interviews. Let's have a look!\n",
    "\n",
    "<img src=\"./images/hired.jpg\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from ipywidgets import interact, fixed, widgets\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (15.0, 15.0)\n",
    "\n",
    "images_path = './images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.1 Laplace operator\n",
    "\n",
    "Compared with the first derivative-based edge detectors such as the Sobel operator, the Laplacian operator may yield better results in edge localization, since it is:\n",
    "- a linear operator,\n",
    "- robust against noise,\n",
    "- precise when localizing objects.\n",
    "\n",
    "The idea behind it is to combine second derivatives in perpendicular directions. Thus, it is defined as:\n",
    "\n",
    "$$ \n",
    "\\nabla^2 f(i,j) =\n",
    "\\frac{\\partial^2}{\\partial x^2}f(i,j) + \n",
    "\\frac{\\partial^2}{\\partial y^2}f(i,j)\n",
    "$$\n",
    "\n",
    "Note that, by definition, **it returns a scalar**, not a vector as in the gradient case. Indeed, the Laplacian is the trace of the *Hessian matrix*, which fully characterizes the second derivative of a function:\n",
    "\n",
    "$$\n",
    "H(f) =\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial f^2}{\\partial x^2} & \\frac{\\partial}{\\partial x}\\frac{\\partial f}{\\partial y} \\\\\n",
    "\\frac{\\partial f}{\\partial y}\\frac{\\partial f}{\\partial x} & \\frac{\\partial f^2}{\\partial y^2}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "### Implementation\n",
    "Now let's have a look to how the Laplacian operator is implemented.\n",
    "\n",
    "1. First derivatives are considered (OpenCV uses Sobel but any is valid): $\\\\[5pt]$\n",
    "\n",
    "$$\\frac{\\partial f(x,y)}{\\partial x} = f_x(x,y) \\approx G_R(i,j) = f(i+1,j) - f(i,j) \\\\[5pt]$$\n",
    "\n",
    "$$\\frac{\\partial f(x,y)}{\\partial y} = f_x(x,y) \\approx G_C(i,j) = f(i,j+1) - f(i,j) \\\\[5pt]$$\n",
    "\n",
    "2. Then, take second derivatives using them:\n",
    "\n",
    "$$g = \\frac{\\partial f^2}{\\partial x^2} = f_{xx}(x,y) \\approx G_R(i,j) - G_R(i-1,j) = f(i+1,j) - 2f(i,j) + f(i-1,j) \\\\[5pt]$$\n",
    "\n",
    "$$h = \\frac{\\partial f^2}{\\partial y^2} = f_{yy}(x,y) \\approx G_C(i,j) - G_C(i-1,j) = f(i,j+1) - 2f(i,j) + f(i,j-1) \\\\[10pt]$$\n",
    "\n",
    "3. Finally, implementing it as a convolution with a certain kernel $L[F(i,j)] = F(i,j) \\otimes L(i,j)$ and applying its distributive property:$\\\\[10pt]$\n",
    "$$\\underbrace{f \\otimes (g + h)}_{\\text{One convolution}} \n",
    "= \n",
    "\\underbrace{(f \\otimes g) + (f \\otimes h)}_{\\text{Two convolutions}}\\\\[10pt]$$\n",
    "\n",
    "The good news is that we can obtain a kernel that carries out both convolutions at once!:\n",
    "\n",
    "<div style=\"margin: 0 auto; text-align: center; display: table;\">\n",
    "<div>\n",
    "    <p><center>g</center></p>\n",
    "    <table style = \"display: table-cell; vertical-align: middle;\">\n",
    "\t<tbody>\n",
    "\t\t<tr>\n",
    "\t\t\t<td style=\"border: 1px solid;\">0</td>\n",
    "\t\t\t<td style=\"border: 1px solid;\">0</td>\n",
    "\t\t\t<td style=\"border: 1px solid;\">0</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td style=\"border: 1px solid;\">1</td>\n",
    "\t\t\t<td style=\"border: 1px solid;\" bgcolor=\"#81F7F3\">-2</td>\n",
    "\t\t\t<td style=\"border: 1px solid;\">1</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td style=\"border: 1px solid;\">0</td>\n",
    "\t\t\t<td style=\"border: 1px solid;\">0</td>\n",
    "\t\t\t<td style=\"border: 1px solid;\">0</td>\n",
    "\t\t</tr>\n",
    "\t</tbody>\n",
    "    </table> \n",
    "</div>\n",
    "    \n",
    "<div style = \"padding: 10px; display: table-cell; vertical-align: middle;\"> $+$ </div>\n",
    "<div>\n",
    "    <p><center>h</center></p>    \n",
    "    <table style = \"display: table-cell; vertical-align: middle;\">\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid;\">0</td>\n",
    "            <td style=\"border: 1px solid;\">1</td>\n",
    "            <td style=\"border: 1px solid;\">0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid;\">0</td>\n",
    "            <td style=\"border: 1px solid;\" bgcolor=\"#81F7F3\">-2</td>\n",
    "            <td style=\"border: 1px solid;\">0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid;\">0</td>\n",
    "            <td style=\"border: 1px solid;\">1</td>\n",
    "            <td style=\"border: 1px solid;\">0</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "    </table> \n",
    "</div>    \n",
    "    \n",
    "<div style = \"padding: 10px; display: table-cell; vertical-align: middle;\"> = </div>\n",
    "<div>\n",
    "    <p><center>g+h=L</center></p>    \n",
    "    <table style = \"display: table-cell; vertical-align: middle;\">\n",
    "\t<tbody>\n",
    "\t\t<tr>\n",
    "\t\t\t<td style=\"border: 1px solid;\">0</td>\n",
    "\t\t\t<td style=\"border: 1px solid;\">1</td>\n",
    "\t\t\t<td style=\"border: 1px solid;\">0</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td style=\"border: 1px solid;\">1</td>\n",
    "\t\t\t<td style=\"border: 1px solid;\" bgcolor=\"#81F7F3\">-4</td>\n",
    "\t\t\t<td style=\"border: 1px solid;\">1</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td style=\"border: 1px solid;\">0</td>\n",
    "\t\t\t<td style=\"border: 1px solid;\">1</td>\n",
    "\t\t\t<td style=\"border: 1px solid;\">0</td>\n",
    "\t\t</tr>\n",
    "\t</tbody>\n",
    "    </table>\n",
    "</div>   \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-crossing\n",
    "\n",
    "Note that after applying that kernel, **it is needed an algorithm to detect zero-crossings** in order to return a binary image of edges. An example of a simple zero-crossing algorithm:\n",
    "\n",
    "> 1. Select a small positive number (threshold) $th$.\n",
    "> 2. A pixel is labelled as an edge if in the Laplacian image:\n",
    ">    - its value is smaller than $-th$ and at least one of its neighbours is bigger that $th$, or\n",
    ">    - its value is bigger than $th$ and at least one of its neighbours is smaller than $-th$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "\n",
    "Unfortunately, the Laplacian operator is very sensitive to noise, resulting in a poor edge detection. Solution: If the image is blurred using a Gaussian filter before applying the Laplace operator, we can partially solve the noise problem. In this case, it is called **LoG (Laplace of Gaussian)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.2 LoG operator\n",
    "\n",
    "So, the LoG operator first smoothes the image, and then applies the Laplacian operator, which applying the convolution properties gets to:\n",
    "\n",
    "$$\n",
    "\\nabla^2[f(x,y)\\otimes g_\\sigma(x,y)] \n",
    "=\n",
    "f(x,y) \\otimes \\nabla^2[g_\\sigma(x,y)]\n",
    "= f(x,y) \\otimes LoG_\\sigma(x,y)\n",
    "$$\n",
    "\n",
    "LoG is an isotropic operator, that is, it keeps radial symmetry. In this way, it is assumed that the covariance in both image dimensions is the same!\n",
    "\n",
    "$$LoG_\\sigma (x,y) = \\frac{1}{\\pi \\sigma^4}\n",
    "\\left[ \\frac{x^2+y^2}{2 \\sigma^2} -1 \\right] \\exp^{-\\frac{x^2+y^2}{2 \\sigma^2}}\n",
    "=\n",
    "\\left[ \\frac{r^2}{2 \\sigma^2} -1 \\right] \\exp^{-\\frac{r^2}{2 \\sigma^2}}\n",
    "= LoG_\\sigma(r^2)\n",
    "$$\n",
    "\n",
    "**Let's print the LoG operator!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gauss filter\n",
    "v = np.arange(-5,5,0.1)\n",
    "X, Y = np.meshgrid(v,v)\n",
    "covar = np.array([[2, 0],[0, 2]]) ## Assuming no correlation between X and Y\n",
    "gauss_filter = np.exp(-0.5*(X**2/covar[0][0]+Y**2/covar[1][1])) \n",
    "\n",
    "# Laplace filter\n",
    "laplace_filter = np.array(([[0,1,0],[1,-4,1],[0,1,0]]), dtype=\"float\")\n",
    "\n",
    "# LoG operator\n",
    "LoG = cv2.filter2D(gauss_filter, -1, laplace_filter)\n",
    "\n",
    "# Plot it!\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_surface(X,Y,LoG,cmap='summer', edgecolor='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a side note, the LoG is not separable, but it can be implemented as **DoG (Difference of Gaussians)**, a sum of separable operators, reducing its complexity from $O(N^2)$ to $O(4N)$:\n",
    "\n",
    "$$\n",
    "DoG_{\\sigma_1\\sigma_2}(x,y) = \n",
    "g_{\\sigma_1}(x,y) - g_{\\sigma_2}(x,y) =\n",
    "g_{\\sigma_1}(x)g_{\\sigma_1}(y) - g_{\\sigma_2}(x) g_{\\sigma_2}(y)\n",
    "$$\n",
    "\n",
    "Giving the ration $\\sigma_1 / \\sigma_2 = 1.6$ the best approximation of LoG. This complexity reduction approach is employed in the SIFT keypoint detector, as we will see in following notebooks.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- It is computationally costly.\n",
    "- It doesn't provide any information about edge orientations.\n",
    "- The output contains negative and non-integer values, so for display purposes the image should be normalized to the range 0-255.\n",
    "- It is needed a zero-crossing method.\n",
    "- It tends to round object corners (more heavily as $\\sigma$ grows)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiencing Laplacian and LoG operators \n",
    "\n",
    "Now that we are almost experts in the Laplacian and LoG operators, let's play a bit with them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 1a: Applying Gaussian smoothing</i></b></span>**\n",
    "\n",
    "First, complete the function `gaussian_smoothing()` that blurs an image using a Gaussian filter. Then, normalizes it and returns the resulting image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ASSIGNMENT 1a\n",
    "# Implement a function that blurres an input image using a Gaussian filter and then normalizes it.\n",
    "def gaussian_smoothing(image, sigma, w_kernel):\n",
    "    \"\"\" Blur and normalize input image.   \n",
    "    \n",
    "        Args:\n",
    "            image: Input image to be binarized\n",
    "            sigma: Standard deviation of the Gaussian distribution\n",
    "            w_kernel: Kernel aperture size\n",
    "                    \n",
    "        Returns: \n",
    "            binarized: Blurred image\n",
    "    \"\"\"   \n",
    "    # Define 1D kernel\n",
    "    \n",
    "    \n",
    "    # Apply distributive property of convolution\n",
    "    \n",
    "    \n",
    "    # Blur image\n",
    "    \n",
    "    \n",
    "    # Normalize to [0 254] values\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to see the differences between the Laplace and LoG operators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 1b: Detecting edges with Laplace and LoG</i></b></span>**\n",
    "\n",
    "Complete `laplace_testing()` that applies the Laplacian operator to the input image and to a blurred version of the input image (use the previously implemented function to smooth it). Display both images along with the original one in a 1x3 plot. Use as inputs: an image, the size of the Laplacian filter (should be odd), and the parameters of the Gaussian filter.\n",
    "\n",
    "Note that it would possible to reduce the computation time if LoG would be precomputed. This is convolving Laplace and Gaussian filters instead of applying them separatelly.\n",
    "\n",
    "*Tip: OpenCV defines Laplace operator as [cv2.Laplacian()](https://docs.opencv.org/3.4/d5/db5/tutorial_laplace_operator.html)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ASSIGNMENT 1b\n",
    "# Implement a function that applies the Laplacian operator to the input image and to a blurred version of it. \n",
    "# Display a 1x3 plot with the original image and the two resulting edge images.\n",
    "# Inputs: image, size of the Laplacian kernel, sigma and size of the Gaussian kernel\n",
    "def laplace_testing(image, size_Laplacian, sigma, w_gaussian):\n",
    "    \"\"\" Apply Laplacian and Log operators to an image.   \n",
    "    \n",
    "        Args:\n",
    "            image: Input image to be binarized\n",
    "            size_Laplacian: size of Laplacian kernel (odd)\n",
    "            sigma: Standard deviation of the Gaussian distribution\n",
    "            w_gaussian: Gaussian kernel aperture size\n",
    "    \"\"\"\n",
    "    \n",
    "    # Blur image\n",
    "    \n",
    "    \n",
    "    # Apply Laplacian to original image\n",
    "    \n",
    "    \n",
    "    # Aplay Laplacian to blurred image\n",
    "    \n",
    "    \n",
    "    # Show initial image\n",
    "    \n",
    "    \n",
    "    # Show laplacian\n",
    "    \n",
    "    \n",
    "    # Show LoG\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to try this method to our medical images and play with interactive parameters.$\\\\[5pt]$      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read an image\n",
    "image = cv2.imread(images_path + 'medical_3.jpg', 0)\n",
    "\n",
    "# Interact with the parameters!\n",
    "interact(laplace_testing, image=fixed(image), size_Laplacian=(1,7,2), sigma=(1,3,0.1), w_gaussian=(1,3,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (1)</i></b></font>\n",
    "\n",
    "Now, **answer the following questions**:\n",
    "\n",
    "- Can be the Laplacian applied without a previous blurring?\n",
    "  \n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "- What would be needed for obtaining the edges from those images?\n",
    "  \n",
    "    <p style=\"margin: 4px 0px 0px 5px; color:blue\"><i>Your answer here!</i></p>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.3 The Canny algorithm\n",
    "\n",
    "The Canny edge detector<sup>[[1]](#cite1)</sup> is an algorithm that applies the DroG operator, non-maxima suppression and hysteresis for edge detection in images. It was designed to be a good detector, yield a good localization, and to provide a single response!\n",
    "\n",
    "This algorithm consists of the following steps:\n",
    "\n",
    "1. *Noise filtering*. Filter out any noise using a Gaussian filter.$\\\\[5pt]$\n",
    "\n",
    "2. *Obtain the gradient image*. Apply the DroG operator.$\\\\[5pt]$\n",
    "\n",
    "3. *Non-maximum suppression* is applied. This removes pixels that are not considered to be part of an edge. Typically, the gradient image obtained after using DroG presents thick edges. The idea is to keep only those pixels that are maximum within their neighborhood in the gradient direction, suppressing the rest of them. Hence, only thin lines (candidate edges) will remain. For that:\n",
    "\n",
    "     - We consider 4 main directions: $[0,45]$, $[45,90]$, $[90,135]$, $[135,180]$. The gradient angle $\\theta[i,j]$ is approximated by where it lays. \n",
    "     - We check the $G[i,j]$ at the three points along the selected direction, and pick the maximum. This way we have a single response at each edge.\n",
    "\n",
    "<img src=\"./images/canny_nonmaxima.png\" width=\"800\">\n",
    "\n",
    "4. *Hysteresis*: The final step. Canny uses two thresholds (upper and lower) to determine edge pixels:\n",
    "\n",
    "    - If the grey level of a candidate pixel of the gradient image is higher than the upper threshold, the pixel is accepted as an edge.\n",
    "    - If the grey level of a candidate pixel of the gradient image is below the lower threshold, then it is rejected.\n",
    "    - If the grey level of a candidate pixel of the gradient image is between the two thresholds, then it will be accepted only if it is connected to a pixel that is above the upper threshold and rejected otherwise.\n",
    "   \n",
    "<img src=\"./images/hysteresis.png\" width=\"800\">\n",
    "\n",
    "The algorithm can be repeated with different level of smoothing (changing the sigma of the DroG operator). Different sigma produces edges at different spatial features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 2: The enormously popular Canny algorithm</i></b></span>**\n",
    "\n",
    "Complete `canny_testing()`, which applies the Canny algorithm to an image and to a blurred version of it *(note that OpenCV Canny's implementation does not apply Gaussian blurring)*. Then both are displayed along the original image. It takes an image, both lower and upper Canny thresholds, and the parameters of the Gaussian filter as input.\n",
    "\n",
    "*Note: use `gaussian_smoothing` to blur the image.*\n",
    "\n",
    "*Tip: OpenCV defines the Canny algorithm as [cv2.Canny()](https://docs.opencv.org/2.4/modules/imgproc/doc/feature_detection.html?highlight=canny)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ASSIGNMENT 2\n",
    "# Implement a function that applies the Canny operator to an input image and to a blurred version of it. \n",
    "# Display a 1x3 plot with the original image and the two resulting edge images.\n",
    "# Inputs: image, size of the Laplacian kernel, sigma and size of the Gaussian kernel\n",
    "def canny_testing(image, lower_threshold, upper_threshold, sigma, w_gaussian):\n",
    "    \"\"\" Apply Canny algorithm to an image.   \n",
    "    \n",
    "        Args:\n",
    "            image: Input image to be binarized\n",
    "            lower_threshold: bottom value for hysteresis\n",
    "            upper_threshold: top value for hysteresis\n",
    "            sigma: Standard deviation of the Gaussian distribution\n",
    "            w_gaussian: Gaussian kernel aperture size\n",
    "    \"\"\"  \n",
    "    \n",
    "    # Blur image\n",
    "    \n",
    "    \n",
    "    # Apply Canny to original image\n",
    "    \n",
    "    \n",
    "    # Apply Canny to blurred image\n",
    "    \n",
    "\n",
    "    # Show initial image\n",
    "    \n",
    "    \n",
    "    # Show Canny without blurring\n",
    "    \n",
    "    \n",
    "    # Show Canny with blurring\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the multiple parameters of this algorithm, it is interesting to check its performance with different levels of smoothing (changing the sigma of the DroG operator). Different sigma produces edges at different spatial features. **Try the effect of this and other parameters** playing with interactive parameters.$\\\\[5pt]$      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read an image\n",
    "image = cv2.imread(images_path + 'medical_2.jpg', 0)\n",
    "\n",
    "# Interact with the parameters\n",
    "interact(canny_testing, image=fixed(image), lower_threshold=(0,260,20), upper_threshold=(0,260,20), sigma=(1,3,0.1), w_gaussian=(1,3,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (2)</i></b></font>\n",
    "\n",
    "Now, **answer following questions**:\n",
    "\n",
    "- Can be Canny applied without a previous blurring?\n",
    "  \n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "- What is a *good* value for both thresholds?\n",
    "  \n",
    "    <p style=\"margin: 4px 0px 0px 5px; color:blue\"><i>Your answer here!</i></p>  \n",
    "    \n",
    "- Now that you have tried a good number of edge detection methods, **which one is your favorite, and why?**\n",
    "\n",
    "    <p style=\"margin: 4px 0px 0px 5px; color:blue\"><i>Your answer here!</i></p>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Terrific! You finished this notebook, that includes information about:\n",
    "\n",
    "- Laplace and LoG operators and the importance of smoothing.\n",
    "- how to use the Canny algorithm, and how it is implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra\n",
    "\n",
    "The Canny algorithm is a very known algorithm in the field, it is used in a lot of current technologies. Although it still gets very good results, the original paper was published in 1986 by John Canny<sup>[[1]](#cite1)</sup>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "<a name=\"myfootnote1\">[1]</a>: CANNY, John. [A computational approach to edge detection.](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=10&ved=2ahUKEwiU9uyiganoAhWNDWMBHducCvsQFjAJegQIBhAB&url=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fdownload%3Fdoi%3D10.1.1.420.3300%26rep%3Drep1%26type%3Dpdf&usg=AOvVaw3tsKoxnc3qnS7bji3HmvQc). IEEE Transactions on pattern analysis and machine intelligence, 1986, no 6, p. 679-698."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
