{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 Contour-based techniques for image segmentation\n",
    "\n",
    "In the previous chapter we had fun with region based techniques for image segmentation, where the resulting segments cover the entire image. In this want we are going to experience **contour-based techniques**, whose are based on detecting specific contours in the image (e.g. circles). In this context, image contours are defined as edge pixels that enclose a region.  \n",
    "\n",
    "Contour-based techniques could be roughly classified into:\n",
    "- **Local tecniques.**\n",
    "   - LoG + zero crossing.\n",
    "   - Edge following (Canny operator).\n",
    "- **Global techniques.**\n",
    "   - Hough transform. \n",
    "   \n",
    "This notebook will cover the **Hough transform** (section 5.2.1), a contour-based technique that can be used for detecting regions with an arbitrary shape in images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem context - Self-driving car \n",
    "\n",
    "A prestigious company located at PTA (The Andalusia Technology Park) is organizing a [hackathon](https://en.wikipedia.org/wiki/Hackathon) for this year in order to motivate college students to make further progress in the autonomous cars field. Computer vision students in UMA decided to take part in it, but the organizers have posed an initial basic task to guarantee that participants have expertise in image processing techniques. \n",
    "\n",
    "This way, the company sent to students a task for **implementing a basic detector road lane lines using OpenCV in python**. We are lucky! These are two tools that we know well ;).\n",
    "\n",
    "Detecting lines in a lane is a fundamental task for autonomous vehicles while driving on the road. It is the building block to other path planning and control actions like breaking and steering. \n",
    "\n",
    "So here we are! We are going to detect road lane lines using Hough transform in OpenCV.$\\\\[5pt]$ \n",
    "\n",
    "<img src=\"./images/car.gif\" width=\"400\" align=\"center\">$\\\\[10pt]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import scipy.stats as stats\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 10.0)\n",
    "images_path = './images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.1 Hough transform\n",
    "\n",
    "The **Hough Transform** if a technique for the detection of arbitrary shapes in an image. For that, such shapes must be expressed in an analytical form (**classic Hough**), e.g. lines, circles, ellipses, etc., or in a numerical form (**generalized Hough**) where the shape is given by a table. Since our goal is to detect lines, we will focus here on analytically expressed shapes. \n",
    "\n",
    "Specifically, a line can be represented analytically as:\n",
    "\n",
    "$$y = mx + n$$\n",
    "\n",
    "or in its parametric form, as:\n",
    "\n",
    "$$\\rho = x \\cos \\theta + y \\sin \\theta$$\n",
    "\n",
    "where $\\rho$ is the perpendicular distance from the origin $(0,0)$ to the line, and $\\theta$ is the angle formed by this perpendicular line and horizontal axis measured in counter-clockwise. Thereby, we are going to represent lines using the pair of parameters $(\\rho, \\theta)$.\n",
    "\n",
    "<img src=\"./images/houghlines.svg\" width=\"250\"/>$\\\\[5pt]$\n",
    "\n",
    "The Hough transform works by a voting procedure, which is carried out in a parameter space ($\\rho,\\theta$ in our case). It works as follows:\n",
    "\n",
    "1. **Build an accumulator matrix**, where rows index the possible values of $\\rho$, and columns those for $\\theta$. *For example, if the possible values for $\\rho$ are $0, 1, 2, \\ldots d$ (where $d$ is the max distance e.g. diagonal size of the image) and those for $\\theta$ are $0, 1, 2 \\ldots 179$, the matrix shape would be $(d,180)$.*\n",
    "2. **Binarize the input image** to obtain pixels that are candidates to belong to the shape contours (e.g. by applying an edge detector).\n",
    "3. For each candidate (white pixel):\n",
    "   1. **Evaluate**: Since the point coordinates $(x,y)$ are known, place them in the line parametric form and iterate over the possible values of $\\theta$ to obtain the values for $\\rho$. In the previous example $\\rho_i = x \\cos \\theta_i + y \\sin \\theta_i, \\forall i\\in[0,180]$\n",
    "   2. **Vote**: For every obtained pair $(\\rho_i, \\theta_i)$ increment by one the value of its associated cell in the accumulator.\n",
    "4. Finally, **obtain the shape candidates** by setting a threshold to control how many votes needs a pair $(\\rho, \\theta)$  to be considered a line, and by applying local maxima in the accumulator space. $\\\\[10pt]$\n",
    "  \n",
    "<img src=\"./images/houghlinesdemo.gif\" width=\"400\" align=\"center\">$\\\\[2pt]$\n",
    "<center><i>Left, image space. Right, parameter space illustrating the evoluation of the votes. Note that in this example $\\theta$ have only 8 possible values.</i></center>\n",
    "\n",
    "The idea behind this algorithm is that when a pixel in the image space votes for all the lines that go through it in the parameter space, when a second pixel belonging to the same line votes, then the line connecting both pixels would have two votes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"orange\">OpenCV pill</font>\n",
    "    \n",
    "OpenCV implements the method [`cv2.HoughLines()`](https://docs.opencv.org/4.2.0/dd/d1a/group__imgproc__feature.html#ga46b4e588934f6c8dfd509cc6e0e4545a) for detecting lines using the Hough transform. However, prior to its usage, and as commented in the `step 1.` of the algorithm, it is needed a binary image. For that we are going to resort to our old friend the Canny algorithm, so the detected edges will be the white pixes in the binary image.\n",
    "\n",
    "As we now, noisy images seriously hamper the performance of computer vision techniques, and since [cv2.Canny](https://docs.opencv.org/4.2.0/dd/d1a/group__imgproc__feature.html#ga04723e007ed888ddf11d9ba04e2232de) does not include blurring, we provide here a method called `gaussian_smoothing()` to assist you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_smoothing(image, sigma, w_kernel):\n",
    "    \"\"\" Blur and normalize input image.   \n",
    "    \n",
    "        Args:\n",
    "            image: Input image to be binarized\n",
    "            sigma: Standard deviation of the Gaussian distribution\n",
    "            w_kernel: Kernel aperture size\n",
    "                    \n",
    "        Returns: \n",
    "            binarized: Blurred image\n",
    "    \"\"\"   \n",
    "    \n",
    "    # Define 1D kernel\n",
    "    s=sigma\n",
    "    w=w_kernel\n",
    "    kernel_1D = [np.exp(-z*z/(2*s*s))/np.sqrt(2*np.pi*s*s) for z in range(-w,w+1)]\n",
    "    \n",
    "    # Apply distributive property of convolution\n",
    "    kernel_2D = np.outer(kernel_1D,kernel_1D)\n",
    "    \n",
    "    # Blur image\n",
    "    smoothed_img = cv2.filter2D(image,cv2.CV_8U,kernel_2D)\n",
    "    \n",
    "    # Normalize to [0 254] values\n",
    "    smoothed_norm = np.array(image.shape)\n",
    "    smoothed_norm = cv2.normalize(smoothed_img,None, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    return smoothed_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 1: Detecting lines with Hough</i></b></span>**\n",
    "\n",
    "**Your first task is** to apply [`cv2.HoughLines()`](https://docs.opencv.org/4.2.0/dd/d1a/group__imgproc__feature.html#ga46b4e588934f6c8dfd509cc6e0e4545a) to the image `car.png`, a test image taken from the frontal camera of a car. Draw the resultant lines using [`cv2.line()`](https://docs.opencv.org/4.2.0/d6/d6e/group__imgproc__draw.html#ga7078a9fae8c7e7d13d24dac2520ae4a2).\n",
    "\n",
    "The main inputs of `cv2.HoughLines()` are:\n",
    "\n",
    "- image: binary input image\n",
    "- rho: distance resolution of the accumulator in pixels (usually 1, it may be bigger for high resolution images) \n",
    "- theta: angle resolution of the accumulator in radians. (usually $\\frac{\\pi}{180}$)$\\\\[2pt]$\n",
    "- threshold: only line candidates having a number of votes $>$ threshold are returned.\n",
    "\n",
    "And it returns:\n",
    "- a  $( n\\_lines x 2 )$ array containing, in each row, the parameters of each detected line.\n",
    "\n",
    "*Note that, for drawing the lines, you have to [transform the resultant lines](https://answers.opencv.org/question/21132/draw-the-lines-detected-by-cvhoughlines/) from the $(\\rho, \\theta)$ space to Cartesian coordinates.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 1\n",
    "# Read the image\n",
    "\n",
    "\n",
    "# Convert to RGB and get gray image\n",
    "\n",
    "\n",
    "# Blur the gray image\n",
    "\n",
    "\n",
    "# Apply Canny algorithm\n",
    "\n",
    "\n",
    "# Search for lines using Hough transform\n",
    "\n",
    "\n",
    "# For each line\n",
    "\n",
    "    \n",
    "    # Transform from polar coordinates to cartesian coordinates\n",
    "    \n",
    "    \n",
    "    # Get two points in that line \n",
    "    \n",
    "    \n",
    "    # Draw the line in the RGB image\n",
    "    \n",
    "\n",
    "# Show resultant image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2.1 Probabilistic Hough transform\n",
    "\n",
    "For high-resolution images and large accumulator sizes the Hough transform may need long execution times. However, in applications like autonomous cars a fast execution is mandatory. For example, having a car moving at 100km/h covers $\\sim28$ meters in a second. Imagine how much lines can change in that time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"orange\">OpenCV pill</font>\n",
    "    \n",
    "OpenCV provides with the method [`cv2.HoughLinesP()`](https://docs.opencv.org/4.2.0/dd/d1a/group__imgproc__feature.html#ga8618180a5948286384e3b7ca02f6feeb) a more complex implementation of the Hough Line Transform, which is called **probabilistic Hough Transform**. This alternative doesnâ€™t take all the points into account, but a random subset of them that are still enough for line detection. This also results in smaller thresholds when deciding if a line exists or not.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 2: Another option for detecting lines</i></b></span>**\n",
    "\n",
    "Apply [`cv2.HoughLinesP()`](https://docs.opencv.org/4.2.0/dd/d1a/group__imgproc__feature.html#ga8618180a5948286384e3b7ca02f6feeb) to the image `car.png` and draw the detected lines.\n",
    "\n",
    "This function returns:\n",
    "- line segments $((x1,y1),(x2,y2))$ instead of the line equation parameters.\n",
    "\n",
    "For that, two additional arguments are needed:\n",
    "- minLineLength: line segments shorter than that are rejected. \n",
    "- maxLineGap: maximum allowed gap between points on the same line to link them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigment 2\n",
    "# Read the image\n",
    "\n",
    "\n",
    "# Convert to RGB and get gray image\n",
    "\n",
    "\n",
    "# Blur the gray image\n",
    "\n",
    "\n",
    "# Apply Canny algorithm\n",
    "\n",
    "\n",
    "# Search for lines using probabilistic Hough transform\n",
    "\n",
    "\n",
    "# For each line\n",
    "\n",
    "    \n",
    "    # Draw the line in RGB image\n",
    "    \n",
    "\n",
    "# Show resultant image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Terrific work! In the road lane lines detection context you have learned:\n",
    "- to detect shapes in images using Hough transform .\n",
    "\n",
    "Also, you obtained some knowledge about: \n",
    "\n",
    "- self-driving cars and computer vision, and\n",
    "- lane line detection for autonomous cars.\n",
    "\n",
    "See you in the next one! Keep learning!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
